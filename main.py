import streamlit as st
import openai
import httpx
import tomllib
import os
from pathlib import Path
from typing import List, Dict
from google import genai
from dotenv import load_dotenv, find_dotenv, set_key

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
env_file = find_dotenv()
load_dotenv(env_file)

# --- é…ç½®ç®¡ç† ---
def load_config() -> dict:
    """åŠ è½½é…ç½®ï¼Œæ”¯æŒ openaiå…¼å®¹æ ¼å¼ / google åˆ†èŠ‚åµŒå¥—ç»“æ„ã€‚"""
    return {
        "provider": os.getenv("PROVIDER", "openai"),
        "proxy_url": os.getenv("PROXY_URL", ""),
        "openai": {
            "api_base": os.getenv("OPENAI_API_BASE", "https://api.mistral.ai/v1"),
            "api_key": os.getenv("OPENAI_API_KEY", ""),
            "model": os.getenv("OPENAI_MODEL", "mistral-medium-latest"),
        },
        "google": {
            "api_key": os.getenv("GOOGLE_API_KEY", ""),
            "model": os.getenv("GOOGLE_MODEL", "gemini-2.5-flash-preview-04-17"),
        },
    }

def save_config(cfg: dict):
    """å°†é…ç½®ä¿å­˜åˆ° .env æ–‡ä»¶ã€‚"""
    global env_file
    if not env_file:
        env_file = Path(".env")
        env_file.touch() # ç¡®ä¿æ–‡ä»¶å­˜åœ¨

    # å°†é…ç½®å­—å…¸ä¸­çš„å€¼é€ä¸€å†™å…¥ .env æ–‡ä»¶
    set_key(env_file, "PROVIDER", cfg.get("provider", "openai"))
    set_key(env_file, "PROXY_URL", cfg.get("proxy_url", ""))
    
    if "openai" in cfg:
        set_key(env_file, "OPENAI_API_KEY", cfg["openai"].get("api_key", ""))
        set_key(env_file, "OPENAI_API_BASE", cfg["openai"].get("api_base", ""))
        set_key(env_file, "OPENAI_MODEL", cfg["openai"].get("model", ""))

    if "google" in cfg:
        set_key(env_file, "GOOGLE_API_KEY", cfg["google"].get("api_key", ""))
        set_key(env_file, "GOOGLE_MODEL", cfg["google"].get("model", ""))

# --- API å®¢æˆ·ç«¯ ---
class LLMClient:
    """ä¸€ä¸ªç»Ÿä¸€çš„ã€ç®€åŒ–çš„LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒOpenAIå…¼å®¹æ¥å£å’ŒGoogle Geminiï¼Œå¹¶ç»Ÿä¸€å¤„ç†ä»£ç†ã€‚"""
    def __init__(self, config: dict):
        self.full_config = config
        self.provider = config.get("provider", "openai")
        proxy_url = config.get("proxy_url")
        provider_cfg = config.get(self.provider)
        self.model = provider_cfg.get("model")
        api_key = provider_cfg.get("api_key")

        if self.provider == "google":
            if proxy_url:
                os.environ["HTTP_PROXY"] = proxy_url
                os.environ["HTTPS_PROXY"] = proxy_url
            self.client = genai.Client(api_key=api_key)
        else:  # openai å…¼å®¹
            http_client = httpx.Client(proxy=proxy_url or None)
            self.client = openai.OpenAI(
                api_key=api_key,
                base_url=provider_cfg.get("api_base", ""),
                http_client=http_client,
            )

    def call(self, messages: List[Dict], **kwargs) -> str:
        """æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”çš„LLM APIã€‚"""
        if self.provider == "google":
            prompt = messages[0]["content"]
            response = self.client.models.generate_content(model=self.model, contents=prompt)
            return response.text
        else:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                **kwargs
            )
            return response.choices[0].message.content

# --- Prompt æ¨¡æ¿ ---
ROLE_INSTRUCTION = "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ä¸“åˆ©ä»£ç†å¸ˆï¼Œæ“…é•¿æ’°å†™ç»“æ„æ¸…æ™°ã€é€»è¾‘ä¸¥è°¨çš„ä¸“åˆ©ç”³è¯·æ–‡ä»¶ã€‚"

# 1. å‘æ˜åç§°
PROMPT_TITLE = (
    f"{ROLE_INSTRUCTION}\nä»»åŠ¡æè¿°ï¼šè¯·æ ¹æ®ä»¥ä¸‹æ ¸å¿ƒæŠ€æœ¯æ„æ€ï¼Œæç‚¼å‡ºç¬¦åˆä¸­å›½ä¸“åˆ©å‘½åè§„èŒƒä¸”ä¸è¶…è¿‡25ä¸ªæ±‰å­—çš„å‘æ˜åç§°ï¼Œè¦æ±‚ç®€æ´æ˜äº†å¹¶å‡†ç¡®åæ˜ æŠ€æœ¯å†…å®¹ã€‚è¯·åªè¿”å›å‘æ˜åç§°æœ¬èº«ï¼Œä¸è¦æ·»åŠ ç¼–å·ã€æ ‡ç‚¹æˆ–å…¶ä»–å¤šä½™æ–‡å­—ã€‚\n\næ ¸å¿ƒæŠ€æœ¯æ„æ€ï¼š\n{{user_input}}"
)

# 2. ç°æœ‰æŠ€æœ¯ï¼ˆèƒŒæ™¯æŠ€æœ¯ï¼‰ç« èŠ‚
PROMPT_BACKGROUND = (
    f"{ROLE_INSTRUCTION}\nä»»åŠ¡æè¿°ï¼šè¯·æ’°å†™â€œäºŒã€ç°æœ‰æŠ€æœ¯ï¼ˆèƒŒæ™¯æŠ€æœ¯ï¼‰â€ç« èŠ‚å†…å®¹ï¼ŒåŒ…å«ï¼š\n2.1 å¯¹æœ€æ¥è¿‘å‘æ˜çš„åŒç±»ç°æœ‰æŠ€æœ¯çŠ¶å†µåŠ ä»¥åˆ†æè¯´æ˜ï¼ˆåŒ…æ‹¬æ„é€ ã€å„éƒ¨ä»¶é—´çš„ä½ç½®å’Œè¿æ¥å…³ç³»ã€å·¥è‰ºè¿‡ç¨‹ç­‰ï¼‰ï¼›\n2.2 å®äº‹æ±‚æ˜¯åœ°æŒ‡å‡ºç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜å¹¶åˆ†æåŸå› ã€‚\nè¯·ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„ä¸­æ–‡ï¼Œå¹¶ä»¥ Markdown æ ¼å¼è¿”å›ã€‚\n\nå‘æ˜åç§°ï¼š{{title}}\næ ¸å¿ƒæŠ€æœ¯æ„æ€ï¼š\n{{user_input}}"
)

# 3. å‘æ˜å†…å®¹ç« èŠ‚
PROMPT_INVENTION_CONTENT = (
    f"{ROLE_INSTRUCTION}\nä»»åŠ¡æè¿°ï¼šè¯·ä¾æ®ä»¥ä¸‹ä¿¡æ¯æ’°å†™â€œä¸‰ã€å‘æ˜å†…å®¹â€ç« èŠ‚ï¼Œå…¶ä¸­åŒ…æ‹¬ï¼š\n3.1 å‘æ˜ç›®çš„ï¼ˆå¯¹åº”2.2ä¸­çš„é—®é¢˜ï¼‰ï¼›\n3.2 æŠ€æœ¯è§£å†³æ–¹æ¡ˆï¼ˆæ¸…æ¥šã€å®Œæ•´ã€å‡†ç¡®åœ°æè¿°æœ¬å‘æ˜çš„æ–¹æ¡ˆå¹¶çªå‡ºåŒºåˆ«äºç°æœ‰æŠ€æœ¯çš„å‘æ˜ç‚¹ï¼‰ï¼›\n3.3 æŠ€æœ¯æ•ˆæœï¼ˆä¸3.1ä¸3.2å¯¹åº”ï¼Œå…·ä½“ã€å®äº‹æ±‚æ˜¯åœ°æè¿°æœ¬å‘æ˜å¯è¾¾åˆ°çš„æ•ˆæœï¼Œæœ€å¥½ç»™å‡ºæ•°æ®ï¼‰ã€‚\nè¯·ä½¿ç”¨ä¸“ä¸šã€ä¸¥è°¨çš„ä¸­æ–‡ï¼Œå¹¶ä»¥ Markdown æ ¼å¼è¿”å›ã€‚\n\nå‘æ˜åç§°ï¼š{{title}}\nèƒŒæ™¯æŠ€æœ¯ï¼š\n{{background}}\næ ¸å¿ƒæŠ€æœ¯æ„æ€ï¼š\n{{user_input}}"
)

# 4. å…·ä½“å®æ–½æ–¹å¼ç« èŠ‚
PROMPT_IMPLEMENTATION = (
    f"{ROLE_INSTRUCTION}\nä»»åŠ¡æè¿°ï¼šè¯·ç»“åˆä»¥ä¸‹ä¿¡æ¯æ’°å†™â€œå››ã€å…·ä½“å®æ–½æ–¹å¼â€ç« èŠ‚ï¼Œè‡³å°‘ä¸¾å‡ºä¸€ä¸ªæ˜ç¡®ä¸”å¯æ“ä½œçš„å…·ä½“å®æ–½ä¾‹ï¼Œå¿…è¦æ—¶ç»“åˆé™„å›¾è¯´æ˜ï¼Œå¹¶è§£é‡Šå‡ºç°çš„è‹±æ–‡ç¼©å†™æˆ–ç‰¹æ®Šä»£å·ã€‚è¯·ä»¥ Markdown æ ¼å¼è¿”å›ã€‚\n\nå‘æ˜åç§°ï¼š{{title}}\nå‘æ˜å†…å®¹ï¼š\n{{invention_content}}\næ ¸å¿ƒæŠ€æœ¯æ„æ€ï¼š\n{{user_input}}"
)

# --- Streamlit åº”ç”¨ç•Œé¢ ---
def render_sidebar(config: dict):
    """æ¸²æŸ“ä¾§è¾¹æ å¹¶è¿”å›æ›´æ–°åçš„é…ç½®å­—å…¸ã€‚"""
    with st.sidebar:
        st.header("âš™ï¸ API é…ç½®")
        provider_map = {"OpenAIå…¼å®¹": "openai", "Google": "google"}
        provider_display = "Google" if config.get("provider") == "google" else "OpenAIå…¼å®¹"
        
        selected_provider = st.radio(
            "æ¨¡å‹æä¾›å•†", options=["OpenAIå…¼å®¹", "Google"], 
            index=list(provider_map.keys()).index(provider_display),
            horizontal=True
        )

        config["provider"] = provider_map[selected_provider]

        p_cfg = config[config["provider"]]
        p_cfg["api_key"] = st.text_input("API Key", value=p_cfg.get("api_key", ""), type="password")

        if config["provider"] == "openai":
            p_cfg["api_base"] = st.text_input("API åŸºç¡€åœ°å€", value=p_cfg.get("api_base", ""))
            p_cfg["model"] = st.text_input("æ¨¡å‹åç§°", value=p_cfg.get("model", ""))
        else:
            p_cfg["model"] = st.text_input("æ¨¡å‹åç§°", value=p_cfg.get("model", "gemini-2.5-flash-preview-04-17"))

        # ä»£ç†é…ç½®å¯¹æ‰€æœ‰æä¾›å•†éƒ½å¯ç”¨
        config["proxy_url"] = st.text_input(
            "ä»£ç† URL (å¯é€‰)", 
            value=config.get("proxy_url", ""), 
            placeholder="http://127.0.0.1:7890",
            help="ä¸ºæ‰€æœ‰APIè¯·æ±‚è®¾ç½®ä»£ç†ã€‚"
        )

        if st.button("ä¿å­˜é…ç½®"):
            save_config(config)
            st.success("é…ç½®å·²ä¿å­˜ï¼")

def main():
    st.set_page_config(page_title="ä¸“åˆ©æ’°å†™åŠ©æ‰‹", layout="wide", page_icon="ğŸ“")
    st.title("ğŸ“ å‘æ˜ä¸“åˆ©ç”³è¯·ä¹¦æ’°å†™åŠ©æ‰‹")

    # åˆå§‹åŒ–é…ç½®ä¸ä¼šè¯çŠ¶æ€
    if "config" not in st.session_state:
        st.session_state.config = load_config()

    # åˆå§‹åŒ–æµç¨‹ç›¸å…³çš„ session_state å˜é‡
    required_session_keys = [
        "stage",         # å½“å‰é˜¶æ®µ
        "user_input",    # æ ¸å¿ƒæŠ€æœ¯æ„æ€
        "title",         # å‘æ˜åç§°
        "background",    # èƒŒæ™¯æŠ€æœ¯
        "invention",     # å‘æ˜å†…å®¹
        "implementation" # å…·ä½“å®æ–½æ–¹å¼
    ]
    for k in required_session_keys:
        if k not in st.session_state:
            st.session_state[k] = ""
    if not st.session_state.stage:
        st.session_state.stage = "input"

    # ä¾§è¾¹æ æ¸²æŸ“
    render_sidebar(st.session_state.config)

    active_provider = st.session_state.config["provider"]
    if not st.session_state.config[active_provider].get("api_key"):
        st.warning("è¯·åœ¨å·¦ä¾§è¾¹æ é…ç½®å¹¶ä¿å­˜æ‚¨çš„ API Keyã€‚")
        st.stop()

    llm_client = LLMClient(st.session_state.config)

    # ----------------------------- é˜¶æ®µä¸€ï¼šè¾“å…¥æ ¸å¿ƒæ„æ€ -----------------------------
    if st.session_state.stage == "input":
        user_input = st.text_area("è¯·è¾“å…¥æ ¸å¿ƒæŠ€æœ¯æ„æ€ã€å‘æ˜ç‚¹ã€é¡¹ç›®ä»‹ç»ç­‰ï¼š", height=300, key="user_input_area")
        if st.button("ğŸ¯ ç”Ÿæˆå‘æ˜åç§°", type="primary") and user_input:
            # è°ƒç”¨ LLM ç”Ÿæˆå‘æ˜åç§°
            messages = [{"role": "user", "content": PROMPT_TITLE.format(user_input=user_input)}]
            with st.spinner("æ­£åœ¨ç”Ÿæˆå‘æ˜åç§°..."):
                title = llm_client.call(messages).strip()
            st.session_state.user_input = user_input
            st.session_state.title = title
            st.session_state.stage = "title"
            st.rerun()

    # ----------------------------- é˜¶æ®µäºŒï¼šç¼–è¾‘/ç¡®è®¤å‘æ˜åç§° -----------------------------
    if st.session_state.stage == "title":
        st.subheader("Step 2ï¸âƒ£  è¯·ç¡®è®¤æˆ–ä¿®æ”¹å‘æ˜åç§°ï¼š")
        edited_title = st.text_input("å‘æ˜åç§°ï¼ˆâ‰¤25å­—ï¼‰ï¼š", value=st.session_state.title, max_chars=25)
        col1, col2 = st.columns(2)
        if col1.button("âœ… ç¡®è®¤å¹¶ç”ŸæˆèƒŒæ™¯æŠ€æœ¯", type="primary"):
            st.session_state.title = edited_title
            # ç”ŸæˆèƒŒæ™¯æŠ€æœ¯
            messages = [{"role": "user", "content": PROMPT_BACKGROUND.format(title=edited_title, user_input=st.session_state.user_input)}]
            with st.spinner("æ­£åœ¨ç”ŸæˆèƒŒæ™¯æŠ€æœ¯ç« èŠ‚..."):
                background = llm_client.call(messages)
            st.session_state.background = background
            st.session_state.stage = "background"
            st.rerun()
        if col2.button("è¿”å›ä¸Šä¸€æ­¥"):
            st.session_state.stage = "input"
            st.rerun()

    # ----------------------------- é˜¶æ®µä¸‰ï¼šèƒŒæ™¯æŠ€æœ¯ç¼–è¾‘/ç¡®è®¤ -----------------------------
    if st.session_state.stage == "background":
        st.subheader("Step 3ï¸âƒ£  è¯·å®¡é˜…å¹¶ä¿®æ”¹èƒŒæ™¯æŠ€æœ¯ç« èŠ‚ï¼š")
        edited_background = st.text_area("äºŒã€ç°æœ‰æŠ€æœ¯ï¼ˆèƒŒæ™¯æŠ€æœ¯ï¼‰ï¼š", value=st.session_state.background, height=500)
        col1, col2 = st.columns(2)
        if col1.button("âœ… ç¡®è®¤å¹¶ç”Ÿæˆå‘æ˜å†…å®¹", type="primary"):
            st.session_state.background = edited_background
            # ç”Ÿæˆå‘æ˜å†…å®¹
            messages = [{"role": "user", "content": PROMPT_INVENTION_CONTENT.format(title=st.session_state.title, background=edited_background, user_input=st.session_state.user_input)}]
            with st.spinner("æ­£åœ¨ç”Ÿæˆå‘æ˜å†…å®¹ç« èŠ‚..."):
                invention_content = llm_client.call(messages)
            st.session_state.invention = invention_content
            st.session_state.stage = "invention"
            st.rerun()
        if col2.button("è¿”å›ä¸Šä¸€æ­¥"):
            st.session_state.stage = "title"
            st.rerun()

    # ----------------------------- é˜¶æ®µå››ï¼šå‘æ˜å†…å®¹ç¼–è¾‘/ç¡®è®¤ -----------------------------
    if st.session_state.stage == "invention":
        st.subheader("Step 4ï¸âƒ£  è¯·å®¡é˜…å¹¶ä¿®æ”¹å‘æ˜å†…å®¹ç« èŠ‚ï¼š")
        edited_invention = st.text_area("ä¸‰ã€å‘æ˜å†…å®¹ï¼š", value=st.session_state.invention, height=600)
        col1, col2 = st.columns(2)
        if col1.button("âœ… ç¡®è®¤å¹¶ç”Ÿæˆå…·ä½“å®æ–½æ–¹å¼", type="primary"):
            st.session_state.invention = edited_invention
            # ç”Ÿæˆå…·ä½“å®æ–½æ–¹å¼
            messages = [{"role": "user", "content": PROMPT_IMPLEMENTATION.format(title=st.session_state.title, invention_content=edited_invention, user_input=st.session_state.user_input)}]
            with st.spinner("æ­£åœ¨ç”Ÿæˆå…·ä½“å®æ–½æ–¹å¼ç« èŠ‚..."):
                implementation = llm_client.call(messages)
            st.session_state.implementation = implementation
            st.session_state.stage = "implementation"
            st.rerun()
        if col2.button("è¿”å›ä¸Šä¸€æ­¥"):
            st.session_state.stage = "background"
            st.rerun()

    # ----------------------------- é˜¶æ®µäº”ï¼šå…·ä½“å®æ–½æ–¹å¼ç¼–è¾‘/ä¸‹è½½ -----------------------------
    if st.session_state.stage == "implementation":
        st.subheader("Step 5ï¸âƒ£  è¯·å®¡é˜…å¹¶ä¿®æ”¹å…·ä½“å®æ–½æ–¹å¼ç« èŠ‚ï¼š")
        edited_implementation = st.text_area("å››ã€å…·ä½“å®æ–½æ–¹å¼ï¼š", value=st.session_state.implementation, height=700)
        col1, col2 = st.columns(2)
        if col1.button("è¿”å›ä¸Šä¸€æ­¥"):
            st.session_state.stage = "invention"
            st.session_state.implementation = edited_implementation
            st.rerun()

        # æ±‡æ€»å…¨æ–‡
        full_text = (
            f"# ä¸€ã€å‘æ˜åç§°\n{st.session_state.title}\n\n" +
            f"## äºŒã€ç°æœ‰æŠ€æœ¯ï¼ˆèƒŒæ™¯æŠ€æœ¯ï¼‰\n{st.session_state.background}\n\n" +
            f"## ä¸‰ã€å‘æ˜å†…å®¹\n{st.session_state.invention}\n\n" +
            f"## å››ã€å…·ä½“å®æ–½æ–¹å¼\n{edited_implementation}"
        )
        st.session_state.implementation = edited_implementation
        if full_text:
            col2.download_button("ğŸ“„ ä¸‹è½½å®Œæ•´è‰ç¨¿", full_text, file_name="patent_draft.md")

if __name__ == "__main__":
    main()
