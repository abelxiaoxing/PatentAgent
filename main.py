import streamlit as st
import openai
import httpx
import os
import json
from pathlib import Path
from typing import List, Dict, Any
from google import genai
from dotenv import load_dotenv, find_dotenv, set_key
import time
import base64
import streamlit.components.v1 as components

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
env_file = find_dotenv()
if not env_file:
    env_file = Path(".env")
    env_file.touch()
load_dotenv(env_file)

def load_config() -> dict:
    """åŠ è½½é…ç½®ï¼Œæ”¯æŒ openaiå…¼å®¹æ ¼å¼ / google åˆ†èŠ‚åµŒå¥—ç»“æ„ã€‚"""
    return {
        "provider": os.getenv("PROVIDER", "openai"),
        "proxy_url": os.getenv("PROXY_URL", ""),
        "openai": {
            "api_base": os.getenv("OPENAI_API_BASE", "https://api.mistral.ai/v1"),
            "api_key": os.getenv("OPENAI_API_KEY", ""),
            "model": os.getenv("OPENAI_MODEL", "mistral-medium-latest"),
        },
        "google": {
            "api_key": os.getenv("GOOGLE_API_KEY", ""),
            "model": os.getenv("GOOGLE_MODEL", "gemini-2.5-flash"),
        },
    }

def save_config(cfg: dict):
    """å°†é…ç½®ä¿å­˜åˆ° .env æ–‡ä»¶ã€‚"""
    set_key(env_file, "PROVIDER", cfg.get("provider", "openai"))
    set_key(env_file, "PROXY_URL", cfg.get("proxy_url", ""))
    if "openai" in cfg:
        set_key(env_file, "OPENAI_API_KEY", cfg["openai"].get("api_key", ""))
        set_key(env_file, "OPENAI_API_BASE", cfg["openai"].get("api_base", ""))
        set_key(env_file, "OPENAI_MODEL", cfg["openai"].get("model", ""))
    if "google" in cfg:
        set_key(env_file, "GOOGLE_API_KEY", cfg["google"].get("api_key", ""))
        set_key(env_file, "GOOGLE_MODEL", cfg["google"].get("model", ""))

class LLMClient:
    """ä¸€ä¸ªç»Ÿä¸€çš„ã€ç®€åŒ–çš„LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒOpenAIå…¼å®¹æ¥å£å’ŒGoogle Geminiï¼Œå¹¶ç»Ÿä¸€å¤„ç†ä»£ç†ã€‚"""
    def __init__(self, config: dict):
        self.full_config = config
        self.provider = config.get("provider", "openai")
        proxy_url = config.get("proxy_url")
        provider_cfg = config.get(self.provider)
        self.model = provider_cfg.get("model")
        api_key = provider_cfg.get("api_key")

        if self.provider == "google":
            if proxy_url:
                os.environ["HTTP_PROXY"] = proxy_url
                os.environ["HTTPS_PROXY"] = proxy_url
            self.client = genai.Client(api_key=api_key)
        else:  # openai å…¼å®¹
            http_client = httpx.Client(proxy=proxy_url or None)
            self.client = openai.OpenAI(
                api_key=api_key,
                base_url=provider_cfg.get("api_base", ""),
                http_client=http_client,
            )

    def call(self, messages: List[Dict], json_mode: bool = False) -> str:
        """æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”çš„LLM API"""
        if self.provider == "google":
            config = {"response_mime_type": "application/json"} if json_mode else {}
            response = self.client.models.generate_content(
                model=self.model, 
                config=config,
                contents=messages[0]["content"],
            )
            return response.text
        else: # openai å…¼å®¹
            extra_params = {"response_format": {"type": "json_object"}} if json_mode else {}
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                **extra_params,
            )
            return response.choices[0].message.content

# --- Prompt æ¨¡æ¿ ---
ROLE_INSTRUCTION = "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ä¸“åˆ©ä»£ç†å¸ˆï¼Œæ“…é•¿æ’°å†™ç»“æ„æ¸…æ™°ã€é€»è¾‘ä¸¥è°¨çš„ä¸“åˆ©ç”³è¯·æ–‡ä»¶ã€‚ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªæ ¼å¼è¦æ±‚ï¼Œç›´æ¥è¾“å‡ºå†…å®¹ï¼Œä¸åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚"

# 0. åˆ†æä»£ç†
PROMPT_ANALYZE = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡æè¿°ï¼šè¯·ä»”ç»†é˜…è¯»å¹¶åˆ†æä»¥ä¸‹æŠ€æœ¯äº¤åº•ææ–™ï¼Œå°†å…¶æ‹†è§£å¹¶æç‚¼æˆä¸€ä¸ªç»“æ„åŒ–çš„JSONå¯¹è±¡ã€‚\n"
    "**é‡è¦ï¼šè¯·ç›´æ¥è¿”å›æœ‰æ•ˆçš„JSONå¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€å‰è¨€æˆ–ä»£ç å—æ ‡è®°ã€‚ä½ çš„å›ç­”å¿…é¡»ä»¥ `{{\n` å¼€å¤´ï¼Œå¹¶ä»¥ `}}` ç»“å°¾ã€‚**\n"
    "JSONç»“æ„åº”åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n"
    "1. `problem_statement`: è¯¥å‘æ˜æ—¨åœ¨è§£å†³çš„ç°æœ‰æŠ€æœ¯ä¸­çš„å…·ä½“é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆ1-2å¥è¯ï¼‰\n"
    "2. `core_inventive_concept`: æœ¬å‘æ˜çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æˆ–æœ€å…³é”®çš„æŠ€æœ¯ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆåŒºåˆ«äºç°æœ‰æŠ€æœ¯çš„æœ¬è´¨ï¼‰\n"
    "3. `technical_solution_summary`: ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬å‘æ˜æå‡ºçš„æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°ï¼ŒåŒ…æ‹¬å…³é”®ç»„ä»¶æˆ–æ­¥éª¤ã€‚\n"
    "4. `key_components_or_steps`: åˆ—å‡ºå®ç°è¯¥æ–¹æ¡ˆæ‰€éœ€çš„ä¸»è¦ç‰©ç†ç»„ä»¶æˆ–å·¥è‰ºæ­¥éª¤çš„æ¸…å•ï¼ˆä½¿ç”¨åˆ—è¡¨æ ¼å¼ï¼‰ã€‚\n"
    "5. `achieved_effects`: ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œæœ¬å‘æ˜èƒ½å¸¦æ¥çš„å…·ä½“ã€å¯é‡åŒ–çš„æœ‰ç›Šæ•ˆæœæ˜¯ä»€ä¹ˆï¼Ÿ\n\n"
    "æŠ€æœ¯äº¤åº•ææ–™ï¼š\n{user_input}"
)

# 1. å‘æ˜åç§°ä»£ç†
PROMPT_TITLE = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡æè¿°ï¼šæ ¹æ®ä»¥ä¸‹æ ¸å¿ƒåˆ›æ–°ç‚¹å’ŒæŠ€æœ¯æ–¹æ¡ˆï¼Œæç‚¼å‡º3ä¸ªç¬¦åˆä¸­å›½ä¸“åˆ©å‘½åè§„èŒƒä¸”ä¸è¶…è¿‡25ä¸ªæ±‰å­—çš„å¤‡é€‰å‘æ˜åç§°ã€‚è¦æ±‚ç®€æ´æ˜äº†å¹¶å‡†ç¡®åæ˜ æŠ€æœ¯å†…å®¹ã€‚\n"
    "**é‡è¦ï¼šè¯·ç›´æ¥è¿”å›ä¸€ä¸ªåŒ…å«3ä¸ªåç§°å­—ç¬¦ä¸²çš„JSONæ•°ç»„ã€‚ç¤ºä¾‹è¾“å‡º: `[\"åç§°ä¸€\", \"åç§°äºŒ\", \"åç§°ä¸‰\"]`**\n\n"
    "æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š{core_inventive_concept}\n"
    "æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°ï¼š{technical_solution_summary}"
)
PROMPT_BACKGROUND_PROBLEM = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šåŸºäºä»¥ä¸‹â€œå¾…è§£å†³çš„æŠ€æœ¯é—®é¢˜â€çš„ç®€è¦é™ˆè¿°ï¼Œæ’°å†™â€œ2.2 ç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜â€æ®µè½ã€‚\n"
    "è¦æ±‚ï¼šå®äº‹æ±‚æ˜¯åœ°æŒ‡å‡ºç°æœ‰æŠ€æœ¯å­˜åœ¨çš„å…·ä½“é—®é¢˜ï¼Œå¹¶å°½å¯èƒ½åˆ†æå…¶åŸå› ã€‚è¯­è¨€ä¸“ä¸šã€å®¢è§‚ã€‚\n"
    "**ç›´æ¥è¾“å‡ºæ®µè½å†…å®¹ï¼Œä¸è¦åŒ…å«æ ‡é¢˜ã€‚**\n\n"
    "å¾…è§£å†³çš„æŠ€æœ¯é—®é¢˜ç®€è¿°ï¼š{problem_statement}"
)
PROMPT_BACKGROUND_CONTEXT = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šåŸºäºä»¥ä¸‹â€œç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜â€çš„è¯¦ç»†æè¿°ï¼Œæ’°å†™â€œ2.1 å¯¹æœ€æ¥è¿‘çš„ç°æœ‰æŠ€æœ¯çŠ¶å†µçš„åˆ†æè¯´æ˜â€æ®µè½ã€‚\n"
    "è¦æ±‚ï¼šåˆ†æä¸è¯¥é—®é¢˜æœ€ç›¸å…³çš„ç°æœ‰æŠ€æœ¯çŠ¶å†µï¼Œä¸ºåé¢æŒ‡å‡ºçš„é—®é¢˜æä¾›ä¸Šä¸‹æ–‡èƒŒæ™¯ã€‚\n"
    "**ç›´æ¥è¾“å‡ºæ®µè½å†…å®¹ï¼Œä¸è¦åŒ…å«æ ‡é¢˜ã€‚**\n\n"
    "ç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜ï¼š\n{background_problem}"
)
PROMPT_INVENTION_PURPOSE = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šå°†ä»¥ä¸‹â€œç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜â€æ®µè½ï¼Œæ”¹å†™ä¸ºâ€œ3.1 å‘æ˜ç›®çš„â€æ®µè½ã€‚\n"
    "è¦æ±‚ï¼šå†…å®¹å¿…é¡»ä¸é—®é¢˜ä¸€ä¸€å¯¹åº”ï¼Œè¯­æ°”ä»æŒ‡å‡ºé—®é¢˜è½¬å˜ä¸ºé˜è¿°æœ¬å‘æ˜è¦è§£å†³çš„ç›®æ ‡ã€‚å¥å¼é€šå¸¸ä»¥â€œåŸºäºæ­¤ï¼Œé’ˆå¯¹ä¸Šè¿°...é—®é¢˜ï¼Œæœ¬å‘æ˜æä¾›/æ—¨åœ¨...â€å¼€å¤´ã€‚\n"
    "**ç›´æ¥è¾“å‡ºæ®µè½å†…å®¹ï¼Œä¸è¦åŒ…å«æ ‡é¢˜ã€‚**\n\n"
    "ç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜ï¼š\n{background_problem}"
)
PROMPT_INVENTION_SOLUTION_POINTS = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šæ ¹æ®â€œæŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°â€å’Œâ€œå…³é”®ç»„ä»¶/æ­¥éª¤æ¸…å•â€ï¼Œæç‚¼å‡ºæœ¬å‘æ˜æŠ€æœ¯æ–¹æ¡ˆçš„æ ¸å¿ƒè¦ç‚¹ã€‚\n"
    "è¦æ±‚ï¼šå°†æ–¹æ¡ˆåˆ†è§£ä¸º3-5ä¸ªé€»è¾‘æ¸…æ™°ã€é«˜åº¦æ¦‚æ‹¬çš„æ­¥éª¤æˆ–ç»„ä»¶è¦ç‚¹ã€‚\n"
    "**é‡è¦ï¼šç›´æ¥è¿”å›ä¸€ä¸ªåŒ…å«å­—ç¬¦ä¸²çš„JSONæ•°ç»„ï¼Œæ¯ä¸ªå­—ç¬¦ä¸²æ˜¯ä¸€ä¸ªè¦ç‚¹ã€‚ç¤ºä¾‹ï¼š`[\"è¦ç‚¹ä¸€ï¼šxxx\", \"è¦ç‚¹äºŒï¼šxxx\"]`**\n\n"
    "æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°ï¼š{technical_solution_summary}\n"
    "å…³é”®ç»„ä»¶/æ­¥éª¤æ¸…å•ï¼š\n{key_components_or_steps}"
)

PROMPT_INVENTION_SOLUTION_DETAIL = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šæ ¹æ®ä»¥ä¸‹æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°ã€æ ¸å¿ƒåˆ›æ–°ç‚¹å’Œå…³é”®ç»„ä»¶/æ­¥éª¤ï¼Œæ’°å†™â€œ3.2 æŠ€æœ¯è§£å†³æ–¹æ¡ˆâ€çš„è¯¦ç»†æ®µè½ã€‚\n"
    "è¦æ±‚ï¼š\n"
    "1. **æ·±å…¥é˜è¿°**ï¼šè¯¦ç»†æè¿°æŠ€æœ¯æ–¹æ¡ˆçš„å®Œæ•´æ¶æ„å’Œå·¥ä½œæµç¨‹ï¼Œè§£é‡Šå„ä¸ªç»„ä»¶æˆ–æ­¥éª¤å¦‚ä½•ååŒå·¥ä½œä»¥å®ç°å‘æ˜ç›®çš„ã€‚\n"
    "2. **åŸç†å’Œå…¬å¼**ï¼šå¿…é¡»ç»“åˆå…·ä½“çš„æŠ€æœ¯å†…å®¹ï¼Œå¼•å…¥å¹¶è§£é‡Šç›¸å…³çš„ç‰©ç†åŸç†ã€æ•°å­¦å…¬å¼æˆ–åŒ–å­¦ååº”å¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ¶‰åŠä¿¡å·å¤„ç†ï¼Œåº”åŒ…å«å‚…é‡Œå¶å˜æ¢æˆ–æ»¤æ³¢å™¨è®¾è®¡çš„å…¬å¼ï¼›å¦‚æœæ¶‰åŠæœºæ¢°ç»“æ„ï¼Œåº”åŒ…å«åŠ›å­¦åˆ†ææˆ–è¿åŠ¨å­¦æ–¹ç¨‹ã€‚å…¬å¼éœ€ä½¿ç”¨LaTeXæ ¼å¼ï¼ˆä¾‹å¦‚ `$$E=mc^2$$`ï¼‰ã€‚\n"
    "3. **é‡åŒ–å’Œç»†èŠ‚**ï¼šå°½å¯èƒ½æä¾›é‡åŒ–çš„å‚æ•°èŒƒå›´ã€å…·ä½“çš„ææ–™é€‰å‹æˆ–ç®—æ³•ä¼ªä»£ç ï¼Œä½¿æè¿°æ›´åŠ å…·ä½“ã€å¯ä¿¡ã€‚\n"
    "4. **é€»è¾‘æ¸…æ™°**ï¼šæ®µè½ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘ä¸¥è°¨ï¼Œå‡†ç¡®åæ˜ æŠ€æœ¯æ–¹æ¡ˆçš„åˆ›æ–°æ€§å’Œå¯è¡Œæ€§ã€‚\n"
    "**ç›´æ¥è¾“å‡ºè¯¦ç»†çš„â€œæŠ€æœ¯è§£å†³æ–¹æ¡ˆâ€æ®µè½å†…å®¹ï¼Œä¸è¦åŒ…å«æ ‡é¢˜ã€‚**\n\n"
    "æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š{core_inventive_concept}\n"
    "æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°ï¼š{technical_solution_summary}\n"
    "å…³é”®ç»„ä»¶/æ­¥éª¤æ¸…å•ï¼š\n{key_components_or_steps}"
)

PROMPT_INVENTION_EFFECTS = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šåŸºäºâ€œæŠ€æœ¯æ–¹æ¡ˆè¦ç‚¹â€å’Œâ€œæœ‰ç›Šæ•ˆæœæ¦‚è¿°â€ï¼Œæ’°å†™â€œ3.3 æŠ€æœ¯æ•ˆæœâ€æ®µè½ã€‚\n"
    "è¦æ±‚ï¼šå°†æŠ½è±¡çš„æœ‰ç›Šæ•ˆæœä¸å…·ä½“çš„æŠ€æœ¯æ–¹æ¡ˆè¦ç‚¹ç»“åˆï¼Œè¯´æ˜æœ¬å‘æ˜å¦‚ä½•é€šè¿‡è¿™äº›è¦ç‚¹å®ç°æ‰€è¿°æ•ˆæœã€‚é€šå¸¸ä»¥â€œåŸºäºä¸Šè¿°æŠ€æœ¯æ–¹æ¡ˆï¼Œç›¸æ¯”äºç°æœ‰æ–¹å¼ï¼Œæœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼šâ€å¼€å¤´ï¼Œå¹¶åˆ†ç‚¹é˜è¿°ã€‚\n"
    "**ç›´æ¥è¾“å‡ºæ®µè½å†…å®¹ï¼Œä¸è¦åŒ…å«æ ‡é¢˜ã€‚**\n\n"
    "æŠ€æœ¯æ–¹æ¡ˆè¦ç‚¹ï¼š\n{solution_points_str}\n"
    "æœ‰ç›Šæ•ˆæœæ¦‚è¿°ï¼š{achieved_effects}"
)

PROMPT_MERMAID_IDEAS = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šåŸºäºä»¥ä¸‹â€œæŠ€æœ¯è§£å†³æ–¹æ¡ˆâ€ï¼Œæ„æ€å‡ºæœ€èƒ½æ¸…æ™°ã€å‡†ç¡®åœ°å±•ç¤ºå‘æ˜ç‚¹çš„é™„å›¾åˆ—è¡¨ã€‚\n"
    "è¦æ±‚ï¼š\n"
    "1. **è¯†åˆ«æ ¸å¿ƒ**: å‡†ç¡®è¯†åˆ«æŠ€æœ¯æ–¹æ¡ˆä¸­çš„å…³é”®æµç¨‹ã€æ ¸å¿ƒç»„ä»¶ã€æˆ–åˆ›æ–°ç»“æ„ã€‚\n"
    "2. **å¤šæ ·åŒ–è§†è§’**: æä¾›è‡³å°‘2ä¸ªã€è‡³å¤š5ä¸ªé™„å›¾æ„æ€ï¼Œåº”è‡³å°‘åŒ…å«ä¸€ä¸ªæ€»ä½“æµç¨‹/ç»“æ„å›¾ï¼Œä»¥åŠè‹¥å¹²ä¸ªå…³é”®æ¨¡å—çš„ç»†èŠ‚å›¾ã€‚\n"
    "3. **æ¸…æ™°æè¿°**: æ¯ä¸ªæ„æ€éœ€åŒ…å«ä¸€ä¸ªç®€æ´çš„`title`ï¼ˆå¦‚â€œç³»ç»Ÿæ€»ä½“æ¶æ„å›¾â€ï¼‰å’Œä¸€ä¸ª`description`ï¼ˆè¯´æ˜è¯¥å›¾æ—¨åœ¨å±•ç¤ºä»€ä¹ˆï¼Œå¸®åŠ©ç»˜å›¾AIç†è§£æ„å›¾ï¼‰ã€‚\n"
    "**é‡è¦ï¼šç›´æ¥è¿”å›ä¸€ä¸ªåŒ…å«æ„æ€å¯¹è±¡çš„JSONæ•°ç»„ã€‚ç¤ºä¾‹ï¼š`[{{\"title\": \"æ„æ€ä¸€æ ‡é¢˜\", \"description\": \"æ„æ€ä¸€æè¿°\"}}]`**\n\n"
    "æŠ€æœ¯è§£å†³æ–¹æ¡ˆè¯¦ç»†æè¿°ï¼š\n{invention_solution_detail}"
)

PROMPT_MERMAID_CODE = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šæ ¹æ®â€œæŠ€æœ¯è§£å†³æ–¹æ¡ˆâ€çš„å®Œæ•´æè¿°å’ŒæŒ‡å®šçš„â€œé™„å›¾æ„æ€â€ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†ã€å‡†ç¡®çš„Mermaidå›¾ä»£ç ã€‚\n"
    "è¦æ±‚ï¼š\n"
    "1. **å‡†ç¡®åæ˜ **: å›¾å¿…é¡»å‡†ç¡®åœ°åæ˜ æŠ€æœ¯æ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯æ„æ€ä¸­è¦æ±‚å±•ç¤ºçš„ç»†èŠ‚ã€‚\n"
    "2. **é€‰æ‹©åˆé€‚çš„å›¾ç±»å‹**: æ ¹æ®æ„æ€å†…å®¹ï¼Œé€‰æ‹©æœ€åˆé€‚çš„Mermaidå›¾ç±»å‹ï¼ˆå¦‚ `graph TD`, `flowchart TD`, `sequenceDiagram`, `componentDiagram` ç­‰ï¼‰ã€‚\n"
    "3. **ä»£ç è´¨é‡**: ç”Ÿæˆçš„Mermaidä»£ç å¿…é¡»è¯­æ³•æ­£ç¡®ã€ç»“æ„æ¸…æ™°ã€æ˜“äºé˜…è¯»ã€‚\n"
    "4. **[] å†…æ¢è¡Œå¤„ç†**: åœ¨ [] å†…æ’å…¥æ¢è¡Œæ—¶ï¼Œä½¿ç”¨åŒå¼•å·åŒ…è£¹å¸¦æ¢è¡Œå†…å®¹çš„å†™æ³•ã€‚ä½¿ç”¨ <br> å®ç°æ¢è¡Œã€‚\n"
    "**é‡è¦ï¼šç›´æ¥è¿”å›Mermaidä»£ç æ–‡æœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—æˆ–ä»£ç å—æ ‡è®° (e.g., ```mermaid)ã€‚**\n\n"
    "é™„å›¾æ„æ€æ ‡é¢˜ï¼š{title}\n"
    "é™„å›¾æ„æ€æè¿°ï¼š{description}\n\n"
    "æŠ€æœ¯è§£å†³æ–¹æ¡ˆå…¨æ–‡å‚è€ƒï¼š\n{invention_solution_detail}"
)

PROMPT_IMPLEMENTATION_POINT = (
    f"{ROLE_INSTRUCTION}\n"
    "ä»»åŠ¡ï¼šä½ æ­£åœ¨æ’°å†™â€œäº”ã€å…·ä½“å®æ–½æ–¹å¼â€ç« èŠ‚ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹è¿™ä¸€ä¸ªæŠ€æœ¯è¦ç‚¹ï¼Œæä¾›ä¸€ä¸ªè¯¦ç»†ã€å¯æ“ä½œçš„å…·ä½“å®ç°æ–¹å¼æè¿°ã€‚\n"
    "è¦æ±‚ï¼šæè¿°åº”å…·ä½“åŒ–ï¼Œå¯åŒ…æ‹¬ä½†ä¸é™äºï¼šå…·ä½“å‚æ•°ã€ç»„ä»¶é€‰å‹ã€æ“ä½œæµç¨‹ã€å·¥ä½œåŸç†ç­‰ï¼Œä½¿æœ¬é¢†åŸŸæŠ€æœ¯äººå‘˜èƒ½å¤Ÿç…§æ­¤å®æ–½ã€‚\n"
    "**ç›´æ¥è¾“å‡ºé’ˆå¯¹è¯¥è¦ç‚¹çš„å…·ä½“å®æ–½æè¿°æ®µè½ï¼Œä¸è¦åŒ…å«æ ‡é¢˜æˆ–ç¼–å·ã€‚**\n\n"
    "å½“å‰è¦è¯¦ç»†é˜è¿°çš„æŠ€æœ¯è¦ç‚¹ï¼š\n{point}"
)

# --- æ–°çš„å·¥ä½œæµä¸UIç« èŠ‚æ˜ å°„ ---
UI_SECTION_ORDER = ["title", "background", "invention", "drawings", "implementation"]

UI_SECTION_CONFIG = {
    "title": {
        "label": "å‘æ˜åç§°",
        "workflow_keys": ["title_options"],
        "dependencies": ["structured_brief"],
    },
    "background": {
        "label": "èƒŒæ™¯æŠ€æœ¯",
        "workflow_keys": ["background_problem", "background_context"],
        "dependencies": ["structured_brief"],
    },
    "invention": {
        "label": "å‘æ˜å†…å®¹",
        "workflow_keys": ["invention_purpose", "solution_points", "invention_solution_detail", "invention_effects"],
        "dependencies": ["background", "structured_brief"],
    },
    "drawings": {
        "label": "é™„å›¾åŠé™„å›¾çš„ç®€å•è¯´æ˜",
        "workflow_keys": ["mermaid_ideas"], # Note: mermaid_codes are handled dynamically
        "dependencies": ["invention"],
    },
    "implementation": {
        "label": "å…·ä½“å®æ–½æ–¹å¼",
        "workflow_keys": ["implementation_details"],
        "dependencies": ["invention", "structured_brief"],
    },
}

WORKFLOW_CONFIG = {
    "title_options": {"prompt": PROMPT_TITLE, "json_mode": True, "dependencies": ["core_inventive_concept", "technical_solution_summary"]},
    "background_problem": {"prompt": PROMPT_BACKGROUND_PROBLEM, "json_mode": False, "dependencies": ["problem_statement"]},
    "background_context": {"prompt": PROMPT_BACKGROUND_CONTEXT, "json_mode": False, "dependencies": ["background_problem"]},
    "invention_purpose": {"prompt": PROMPT_INVENTION_PURPOSE, "json_mode": False, "dependencies": ["background_problem"]},
    "solution_points": {"prompt": PROMPT_INVENTION_SOLUTION_POINTS, "json_mode": True, "dependencies": ["technical_solution_summary", "key_components_or_steps"]},
    "invention_solution_detail": {"prompt": PROMPT_INVENTION_SOLUTION_DETAIL, "json_mode": False, "dependencies": ["core_inventive_concept", "technical_solution_summary", "key_components_or_steps"]},
    "invention_effects": {"prompt": PROMPT_INVENTION_EFFECTS, "json_mode": False, "dependencies": ["solution_points", "achieved_effects"]},
    "mermaid_ideas": {"prompt": PROMPT_MERMAID_IDEAS, "json_mode": True, "dependencies": ["invention_solution_detail"]},
    "implementation_details": {"prompt": PROMPT_IMPLEMENTATION_POINT, "json_mode": False, "dependencies": ["solution_points"]},
}

# --- çŠ¶æ€ç®¡ç†ä¸ä¾èµ–æ£€æŸ¥ ---
def get_active_content(key: str) -> Any:
    """è·å–æŸä¸ªéƒ¨åˆ†å½“å‰æ¿€æ´»ç‰ˆæœ¬çš„å†…å®¹ã€‚"""
    if f"{key}_versions" not in st.session_state or not st.session_state[f"{key}_versions"]:
        return None
    active_index = st.session_state.get(f"{key}_active_index", 0)
    return st.session_state[f"{key}_versions"][active_index]

def is_stale(ui_key: str) -> bool:
    """æ£€æŸ¥æŸä¸ªUIç« èŠ‚æ˜¯å¦å› å…¶ä¾èµ–é¡¹æ›´æ–°è€Œè¿‡æ—¶ã€‚"""
    timestamps = st.session_state.data_timestamps
    if ui_key not in timestamps:
        return False 
    
    section_time = timestamps[ui_key]
    for dep in UI_SECTION_CONFIG[ui_key]["dependencies"]:
        if dep in timestamps and timestamps[dep] > section_time:
            return True
    if 'structured_brief' in UI_SECTION_CONFIG[ui_key]["dependencies"]:
        if 'structured_brief' in timestamps and timestamps['structured_brief'] > section_time:
            return True
    return False

# --- æ ¸å¿ƒå·¥ä½œæµä¸UIæ¸²æŸ“ ---
def initialize_session_state():
    """åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„ä¼šè¯çŠ¶æ€å˜é‡ã€‚"""
    if "stage" not in st.session_state:
        st.session_state.stage = "input"
    if "config" not in st.session_state:
        st.session_state.config = load_config()
    if "user_input" not in st.session_state:
        st.session_state.user_input = ""
    if "structured_brief" not in st.session_state:
        st.session_state.structured_brief = {}
    if "data_timestamps" not in st.session_state:
        st.session_state.data_timestamps = {}
    if "mermaid_drawings" not in st.session_state:
        st.session_state.mermaid_drawings = {} # {idea_title: {"code": "...", "description": "..."}}

    all_keys = list(UI_SECTION_CONFIG.keys()) + list(WORKFLOW_CONFIG.keys())
    for key in all_keys:
        if f"{key}_versions" not in st.session_state:
            st.session_state[f"{key}_versions"] = []
        if f"{key}_active_index" not in st.session_state:
            st.session_state[f"{key}_active_index"] = 0

def render_sidebar(config: dict):
    """æ¸²æŸ“ä¾§è¾¹æ å¹¶è¿”å›æ›´æ–°åçš„é…ç½®å­—å…¸ã€‚"""
    with st.sidebar:
        st.header("âš™ï¸ API é…ç½®")
        provider_map = {"OpenAIå…¼å®¹": "openai", "Google": "google"}
        provider_keys = list(provider_map.keys())
        current_provider_key = next((key for key, value in provider_map.items() if value == config.get("provider")), "OpenAIå…¼å®¹")
        
        selected_provider_display = st.radio(
            "æ¨¡å‹æä¾›å•†", options=provider_keys, 
            index=provider_keys.index(current_provider_key),
            horizontal=True
        )
        config["provider"] = provider_map[selected_provider_display]

        p_cfg = config[config["provider"]]
        p_cfg["api_key"] = st.text_input("API Key", value=p_cfg.get("api_key", ""), type="password", key=f"{config['provider']}_api_key")

        if config["provider"] == "openai":
            p_cfg["api_base"] = st.text_input("API åŸºç¡€åœ°å€", value=p_cfg.get("api_base", ""), key="openai_api_base")
            p_cfg["model"] = st.text_input("æ¨¡å‹åç§°", value=p_cfg.get("model", ""), key="openai_model")
        else:
            p_cfg["model"] = st.text_input("æ¨¡å‹åç§°", value=p_cfg.get("model", ""), key="google_model")

        config["proxy_url"] = st.text_input(
            "ä»£ç† URL (å¯é€‰)", value=config.get("proxy_url", ""), 
            placeholder="http://127.0.0.1:7890"
        )

        if st.button("ä¿å­˜é…ç½®"):
            save_config(config)
            st.success("é…ç½®å·²ä¿å­˜ï¼")
            if 'llm_client' in st.session_state:
                del st.session_state.llm_client
            st.rerun()

def generate_ui_section(llm_client: LLMClient, ui_key: str):
    """ä¸ºå•ä¸ªUIç« èŠ‚æ‰§è¡Œå…¶èƒŒåçš„å®Œæ•´å¾®ä»»åŠ¡æµï¼Œå¹¶ç»„è£…æœ€ç»ˆå†…å®¹ã€‚"""
    if ui_key == "drawings": # Drawings section has its own logic
        return

    brief = st.session_state.structured_brief
    workflow_keys = UI_SECTION_CONFIG[ui_key]["workflow_keys"]

    for micro_key in workflow_keys:
        step_config = WORKFLOW_CONFIG[micro_key]
        
        format_args = {**brief}
        for dep in step_config["dependencies"]:
            format_args[dep] = get_active_content(dep) or brief.get(dep)

        if "key_components_or_steps" in step_config["dependencies"]:
            format_args["key_components_or_steps"] = "\n".join(brief.get('key_components_or_steps', []))
        if micro_key == "invention_effects":
            solution_points = get_active_content("solution_points") or []
            format_args["solution_points_str"] = "\n".join([f"{i+1}. {p}" for i, p in enumerate(solution_points)])

        if micro_key == "implementation_details":
            points = get_active_content("solution_points") or []
            details = []
            for i, point in enumerate(points):
                point_prompt = step_config["prompt"].format(point=point)
                detail = llm_client.call([{"role": "user", "content": point_prompt}], json_mode=False)
                details.append(detail)
            
            st.session_state[f"{micro_key}_versions"].append(details)
            st.session_state[f"{micro_key}_active_index"] = len(st.session_state[f"{micro_key}_versions"]) - 1
            st.session_state.data_timestamps[micro_key] = time.time()
            continue

        prompt = step_config["prompt"].format(**format_args)
        response_str = llm_client.call([{"role": "user", "content": prompt}], json_mode=step_config["json_mode"])
        
        try:
            result = json.loads(response_str.strip()) if step_config["json_mode"] else response_str.strip()
        except json.JSONDecodeError:
            st.error(f"æ— æ³•è§£æJSONï¼Œæ¨¡å‹è¿”å›å†…å®¹: {response_str}")
            return
        
        st.session_state[f"{micro_key}_versions"].append(result)
        st.session_state[f"{micro_key}_active_index"] = len(st.session_state[f"{micro_key}_versions"]) - 1
        st.session_state.data_timestamps[micro_key] = time.time()

    final_content = ""
    if ui_key == "title":
        final_content = get_active_content("title_options")
    elif ui_key == "background":
        context = get_active_content("background_context")
        problem = get_active_content("background_problem")
        final_content = f"## 2.1 å¯¹æœ€æ¥è¿‘å‘æ˜çš„åŒç±»ç°æœ‰æŠ€æœ¯çŠ¶å†µåŠ ä»¥åˆ†æè¯´æ˜\n{context}\n\n## 2.2 å®äº‹æ±‚æ˜¯åœ°æŒ‡å‡ºç°æœ‰æŠ€æœ¯å­˜åœ¨çš„é—®é¢˜ï¼Œå°½å¯èƒ½åˆ†æå­˜åœ¨çš„åŸå› ã€‚\n{problem}"
    elif ui_key == "invention":
        purpose = get_active_content("invention_purpose")
        solution_detail = get_active_content("invention_solution_detail")
        effects = get_active_content("invention_effects")
        final_content = f"## 3.1 å‘æ˜ç›®çš„\n{purpose}\n\n## 3.2 æŠ€æœ¯è§£å†³æ–¹æ¡ˆ\n{solution_detail}\n\n## 3.3 æŠ€æœ¯æ•ˆæœ\n{effects}"
    elif ui_key == "implementation":
        details = get_active_content("implementation_details") or []
        final_content = "\n\n".join([f"{i+1}. {detail}" for i, detail in enumerate(details)])

    if ui_key == "title":
        st.session_state.title_versions.extend(final_content)
        st.session_state.title_active_index = len(st.session_state.title_versions) - 1
    else:
        st.session_state[f"{ui_key}_versions"].append(final_content)
        st.session_state[f"{ui_key}_active_index"] = len(st.session_state[f"{ui_key}_versions"]) - 1
    
    st.session_state.data_timestamps[ui_key] = time.time()

def main():
    st.set_page_config(page_title="æ™ºèƒ½ä¸“åˆ©æ’°å†™åŠ©æ‰‹ v2", layout="wide", page_icon="ğŸ“")
    st.title("ğŸ“ æ™ºèƒ½ä¸“åˆ©ç”³è¯·ä¹¦æ’°å†™åŠ©æ‰‹ v2")
    st.caption("æ–°å¢é™„å›¾ç”ŸæˆåŠŸèƒ½ï¼Œæ”¯æŒåˆ†æ­¥æ„æ€ã€ç‹¬ç«‹ç”Ÿæˆå’Œä¸‹è½½")

    initialize_session_state()
    config = st.session_state.config
    render_sidebar(config)

    active_provider = st.session_state.config["provider"]
    if not st.session_state.config.get(active_provider, {}).get("api_key"):
        st.warning("è¯·åœ¨å·¦ä¾§è¾¹æ é…ç½®å¹¶ä¿å­˜æ‚¨çš„ API Keyã€‚")
        st.stop()

    if 'llm_client' not in st.session_state:
        st.session_state.llm_client = LLMClient(st.session_state.config)
    llm_client = st.session_state.llm_client

    # --- é˜¶æ®µä¸€ï¼šè¾“å…¥æ ¸å¿ƒæ„æ€ ---
    if st.session_state.stage == "input":
        st.header("Step 1ï¸âƒ£: è¾“å…¥æ ¸å¿ƒæŠ€æœ¯æ„æ€")
        user_input = st.text_area(
            "åœ¨æ­¤å¤„ç²˜è´´æ‚¨çš„æŠ€æœ¯äº¤åº•ã€é¡¹ç›®ä»‹ç»ã€æˆ–ä»»ä½•æè¿°å‘æ˜çš„æ–‡å­—ï¼š",
            value=st.session_state.user_input,
            height=250,
            key="user_input_area"
        )
        if st.button("ğŸ”¬ åˆ†æå¹¶æç‚¼æ ¸å¿ƒè¦ç´ ", type="primary"):
            if user_input:
                st.session_state.user_input = user_input
                prompt = PROMPT_ANALYZE.format(user_input=user_input)
                with st.spinner("æ­£åœ¨è°ƒç”¨åˆ†æä»£ç†ï¼Œè¯·ç¨å€™..."):
                    try:
                        response_str = llm_client.call([{"role": "user", "content": prompt}], json_mode=True)
                        st.session_state.structured_brief = json.loads(response_str.strip())
                        st.session_state.stage = "review_brief"
                        st.rerun()
                    except (json.JSONDecodeError, KeyError) as e:
                        st.error(f"æ— æ³•è§£ææ¨¡å‹è¿”å›çš„æ ¸å¿ƒè¦ç´ ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºæˆ–å°è¯•è°ƒæ•´è¾“å…¥ã€‚é”™è¯¯: {e}\næ¨¡å‹åŸå§‹è¿”å›: \n{response_str}")
            else:
                st.warning("è¯·è¾“å…¥æ‚¨çš„æŠ€æœ¯æ„æ€ã€‚")

    # --- é˜¶æ®µäºŒï¼šå®¡æ ¸å¹¶ç¡®è®¤æ ¸å¿ƒè¦ç´  ---
    if st.session_state.stage == "review_brief":
        st.header("Step 2ï¸âƒ£: å®¡æ ¸æ ¸å¿ƒè¦ç´ å¹¶é€‰æ‹©æ¨¡å¼")
        st.info("è¯·æ£€æŸ¥å¹¶ç¼–è¾‘AIæç‚¼çš„å‘æ˜æ ¸å¿ƒä¿¡æ¯ã€‚æ‚¨çš„ä¿®æ”¹å°†è‡ªåŠ¨è§¦å‘ä¾èµ–æ›´æ–°æç¤ºã€‚")
        
        brief = st.session_state.structured_brief
        def update_brief_timestamp():
            st.session_state.data_timestamps['structured_brief'] = time.time()

        brief['problem_statement'] = st.text_area("1. å¾…è§£å†³çš„æŠ€æœ¯é—®é¢˜", value=brief.get('problem_statement', ''), on_change=update_brief_timestamp)
        brief['core_inventive_concept'] = st.text_area("2. æ ¸å¿ƒåˆ›æ–°ç‚¹", value=brief.get('core_inventive_concept', ''), on_change=update_brief_timestamp)
        brief['technical_solution_summary'] = st.text_area("3. æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°", value=brief.get('technical_solution_summary', ''), on_change=update_brief_timestamp)
        key_steps_list = brief.get('key_components_or_steps', [])
        key_steps_str = "\n".join(key_steps_list) if isinstance(key_steps_list, list) else key_steps_list
        edited_steps_str = st.text_area("4. å…³é”®ç»„ä»¶/æ­¥éª¤æ¸…å•", value=key_steps_str, on_change=update_brief_timestamp)
        brief['key_components_or_steps'] = [line.strip() for line in edited_steps_str.split('\n') if line.strip()]
        brief['achieved_effects'] = st.text_area("5. æœ‰ç›Šæ•ˆæœ", value=brief.get('achieved_effects', ''), on_change=update_brief_timestamp)

        col1, col2, col3 = st.columns([2,2,1])
        if col1.button("ğŸš€ ä¸€é”®ç”Ÿæˆåˆç¨¿", type="primary"):
            with st.status("æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆå®Œæ•´ä¸“åˆ©åˆç¨¿...", expanded=True) as status:
                for key in UI_SECTION_ORDER:
                    if key == 'drawings': continue
                    status.update(label=f"æ­£åœ¨ç”Ÿæˆ: {UI_SECTION_CONFIG[key]['label']}...")
                    generate_ui_section(llm_client, key)
                status.update(label="âœ… æ‰€æœ‰ç« èŠ‚ç”Ÿæˆå®Œæ¯•ï¼", state="complete")
            st.session_state.stage = "writing"
            st.rerun()

        if col2.button("âœï¸ è¿›å…¥åˆ†æ­¥ç²¾ä¿®æ¨¡å¼"):
            st.session_state.stage = "writing"
            st.rerun()
        
        if col3.button("è¿”å›é‡æ–°è¾“å…¥"):
            st.session_state.stage = "input"
            st.rerun()

    # --- é˜¶æ®µä¸‰ï¼šåˆ†æ­¥ç”Ÿæˆä¸æ’°å†™ ---
    if st.session_state.stage == "writing":
        st.header("Step 3ï¸âƒ£: é€ç« ç”Ÿæˆä¸ç¼–è¾‘ä¸“åˆ©è‰ç¨¿")
        
        if st.button("â¬…ï¸ è¿”å›ä¿®æ”¹æ ¸å¿ƒè¦ç´ "):
            st.session_state.stage = "review_brief"
            st.rerun()
        
        st.markdown("---")
        just_generated_key = st.session_state.pop('just_generated_key', None)

        for key in UI_SECTION_ORDER:
            config = UI_SECTION_CONFIG[key]
            label = config["label"]
            versions = st.session_state.get(f"{key}_versions", [])
            is_section_stale = is_stale(key)
            
            expander_label = f"**{label}**"
            if is_section_stale:
                expander_label += " âš ï¸ (ä¾èµ–é¡¹å·²æ›´æ–°ï¼Œå»ºè®®é‡æ–°ç”Ÿæˆ)"
            elif not versions and key != 'drawings':
                expander_label += " (å¾…ç”Ÿæˆ)"
            
            is_expanded = (not versions and key != 'drawings') or is_section_stale or (key == just_generated_key) or (key == 'drawings' and bool(get_active_content('invention')))
            with st.expander(expander_label, expanded=is_expanded):
                # --- ç‰¹æ®Šå¤„ç†é™„å›¾ç« èŠ‚ ---
                if key == 'drawings':
                    invention_solution_detail = get_active_content("invention_solution_detail")
                    if not invention_solution_detail:
                        st.info("è¯·å…ˆç”Ÿæˆâ€œå‘æ˜å†…å®¹â€ç« èŠ‚ä¸­çš„â€œæŠ€æœ¯è§£å†³æ–¹æ¡ˆâ€ã€‚")
                        continue

                    # 1. æ„æ€é™„å›¾
                    if st.button("ğŸ’¡ æ„æ€é™„å›¾åˆ—è¡¨"):
                        with st.spinner("æ­£åœ¨æ„æ€é™„å›¾..."):
                            prompt = PROMPT_MERMAID_IDEAS.format(invention_solution_detail=invention_solution_detail)
                            response_str = llm_client.call([{"role": "user", "content": prompt}], json_mode=True)
                            try:
                                ideas = json.loads(response_str.strip())
                                st.session_state.mermaid_ideas_versions.append(ideas)
                                st.session_state.mermaid_ideas_active_index = len(st.session_state.mermaid_ideas_versions) - 1
                                st.session_state.mermaid_drawings = {} # æ¸…ç©ºæ—§å›¾
                                st.rerun()
                            except json.JSONDecodeError:
                                st.error(f"æ— æ³•è§£æé™„å›¾æ„æ€åˆ—è¡¨: {response_str}")

                    ideas = get_active_content("mermaid_ideas")
                    if ideas:
                        st.markdown("---")
                        st.subheader("é™„å›¾æ„æ€æ¸…å•")
                        st.caption("è¯·é€‰æ‹©ä¸€ä¸ªæ„æ€ï¼ŒAIå°†ä¸ºå…¶ç”Ÿæˆå¯¹åº”çš„Mermaidå›¾ã€‚")
                        
                        for i, idea in enumerate(ideas):
                            idea_title = idea.get('title', f"æ„æ€ {i+1}")
                            st.markdown(f"**{idea_title}**")
                            st.markdown(f"*{idea.get('description')}*")
                            
                            if st.button(f"âœï¸ ç”Ÿæˆæ­¤å›¾", key=f"gen_mermaid_{i}"):
                                with st.spinner(f"æ­£åœ¨ä¸ºâ€œ{idea_title}â€ç”ŸæˆMermaidä»£ç ..."):
                                    prompt = PROMPT_MERMAID_CODE.format(
                                        title=idea_title,
                                        description=idea.get('description', ''),
                                        invention_solution_detail=invention_solution_detail
                                    )
                                    code = llm_client.call([{"role": "user", "content": prompt}], json_mode=False)
                                    st.session_state.mermaid_drawings[idea_title] = {
                                        "code": code.strip(),
                                        "description": ""
                                    }
                                    st.rerun()
                            st.markdown("---")

                    if st.session_state.mermaid_drawings:
                        st.subheader("å·²ç”Ÿæˆé™„å›¾")
                        for i, (title, drawing) in enumerate(st.session_state.mermaid_drawings.items()):
                            with st.container(border=True):
                                st.markdown(f"**{title}**")

                                drawing_key = f"mermaid_{i}"
                                safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '_')).rstrip()

                                html_component = f'''
                                    <div id="mermaid-view-{drawing_key}">
                                        <div id="mermaid-output-{drawing_key}" style="background-color: white; padding: 1rem; border-radius: 0.5rem;"></div>
                                    </div>
                                    
                                    <button id="download-btn-{drawing_key}" style="margin-top: 10px; padding: 5px 10px; border-radius: 5px; border: 1px solid #ccc; cursor: pointer;">ğŸ“¥ ä¸‹è½½ PNG</button>

                                    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
                                    <script>
                                    (function() {{
                                        const drawingKey = "{drawing_key}";
                                        const pngFileName = "{safe_title}.png";
                                        const code = `{drawing["code"].replace("`", "`")}`;
                                        
                                        const outputDiv = document.getElementById(`mermaid-output-${{drawingKey}}`);
                                        const downloadBtn = document.getElementById(`download-btn-${{drawingKey}}`);

                                        const renderDiagram = async () => {{
                                            try {{
                                                mermaid.initialize({{ startOnLoad: false, theme: 'base', themeVariables: {{ 'background': 'white' }} }});
                                                const {{ svg }} = await mermaid.render(`mermaid-svg-${{drawingKey}}`, code);
                                                outputDiv.innerHTML = svg;
                                            }} catch (e) {{
                                                outputDiv.innerHTML = `<pre style="color: red;">Error rendering diagram:\n${{e.message}}</pre>`;
                                                console.error("Mermaid render error:", e);
                                            }}
                                        }};

                                        const downloadPNG = async () => {{
                                            try {{
                                                const svgElement = outputDiv.querySelector('svg');
                                                if (!svgElement) {{
                                                    alert("Diagram not rendered yet. Cannot download.");
                                                    return;
                                                }}
                                                
                                                const svgData = new XMLSerializer().serializeToString(svgElement);
                                                const img = new Image();
                                                const canvas = document.createElement('canvas');
                                                const ctx = canvas.getContext('2d');

                                                img.onload = function() {{
                                                    const scale = 2; // Higher resolution
                                                    const rect = svgElement.getBoundingClientRect();
                                                    canvas.width = rect.width * scale;
                                                    canvas.height = rect.height * scale;
                                                    
                                                    ctx.fillStyle = 'white';
                                                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                                                    ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

                                                    const pngFile = canvas.toDataURL('image/png');
                                                    const downloadLink = document.createElement('a');
                                                    downloadLink.download = pngFileName;
                                                    downloadLink.href = pngFile;
                                                    document.body.appendChild(downloadLink);
                                                    downloadLink.click();
                                                    document.body.removeChild(downloadLink);
                                                }};
                                                img.src = `data:image/svg+xml;base64,${{btoa(unescape(encodeURIComponent(svgData)))}}`;
                                            }} catch (e) {{
                                                console.error("Download failed:", e);
                                                alert(`Failed to generate PNG: ${{e.message}}`);
                                            }}
                                        }};

                                        renderDiagram();
                                        downloadBtn.addEventListener('click', downloadPNG);
                                    }})();
                                    </script>
                                '''
                                components.html(html_component, height=450, scrolling=True)
                                
                                edited_code = st.text_area("ç¼–è¾‘Mermaidä»£ç :", value=drawing["code"], key=f"edit_code_{title}", height=150)
                                if edited_code != drawing["code"]:
                                    st.session_state.mermaid_drawings[title]["code"] = edited_code
                                    st.rerun()

                                edited_desc = st.text_input("é™„å›¾çš„ç®€å•è¯´æ˜:", value=drawing.get("description", ""), key=f"edit_desc_{title}")
                                if edited_desc != drawing.get("description", ""):
                                    st.session_state.mermaid_drawings[title]["description"] = edited_desc
                                    st.rerun()
                    continue
                
                # --- å¸¸è§„ç« èŠ‚å¤„ç† ---
                col1, col2 = st.columns([3, 1])
                with col1:
                    deps_met = all(get_active_content(dep) or (dep == 'structured_brief' and st.session_state.structured_brief) for dep in config["dependencies"])
                    if deps_met:
                        if st.button(f"ğŸ”„ é‡æ–°ç”Ÿæˆ {label}" if versions else f"âœï¸ ç”Ÿæˆ {label}", key=f"btn_{key}"):
                            with st.spinner(f"æ­£åœ¨è°ƒç”¨ {label} ä»£ç†..."):
                                generate_ui_section(llm_client, key)
                                st.session_state.just_generated_key = key
                                st.rerun()
                    else:
                        st.info(f"è¯·å…ˆç”Ÿæˆå‰ç½®ç« èŠ‚ã€‚")

                with col2:
                    if len(versions) > 1:
                        active_idx = st.session_state.get(f"{key}_active_index", 0)
                        new_idx = st.selectbox(f"é€‰æ‹©ç‰ˆæœ¬ (å…±{len(versions)}ä¸ª)", range(len(versions)), index=active_idx, format_func=lambda x: f"ç‰ˆæœ¬ {x+1}", key=f"select_{key}")
                        if new_idx != active_idx:
                            st.session_state[f"{key}_active_index"] = new_idx
                            st.rerun()

                if versions:
                    active_content = get_active_content(key)
                    
                    def create_new_version(k, new_content):
                        st.session_state[f"{k}_versions"].append(new_content)
                        st.session_state[f"{k}_active_index"] = len(st.session_state[f"{k}_versions"]) - 1
                        st.session_state.data_timestamps[k] = time.time()

                    if key == 'title':
                        edited_content = st.text_input("ç¼–è¾‘åŒº", value=active_content, key=f"edit_{key}")
                    else:
                        edited_content = st.text_area("ç¼–è¾‘åŒº", value=active_content, height=300, key=f"edit_{key}")
                    
                    if edited_content != active_content:
                        create_new_version(key, edited_content)
                        st.rerun()

    # --- é˜¶æ®µå››ï¼šé¢„è§ˆä¸ä¸‹è½½ ---
    if st.session_state.stage == "writing" and all(get_active_content(key) for key in ["title", "background", "invention", "implementation"]):
        st.header("Step 4ï¸âƒ£: é¢„è§ˆä¸ä¸‹è½½")
        st.markdown("---")
        
        title = get_active_content('title')
        
        # æ„å»ºé™„å›¾ç« èŠ‚
        drawings_text = ""
        if st.session_state.mermaid_drawings:
            for i, (drawing_title, drawing_data) in enumerate(st.session_state.mermaid_drawings.items()):
                drawings_text += f"## é™„å›¾{i+1}ï¼š{drawing_title}\n"
                drawings_text += f"```mermaid\n{drawing_data['code']}\n```\n"
                if drawing_data.get('description'):
                    drawings_text += f"**é™„å›¾{i+1}çš„ç®€å•è¯´æ˜**ï¼š{drawing_data['description']}\n\n"

        full_text = (
            f"# ä¸€ã€å‘æ˜åç§°\n{title}\n\n"
            f"# äºŒã€ç°æœ‰æŠ€æœ¯ï¼ˆèƒŒæ™¯æŠ€æœ¯ï¼‰\n{get_active_content('background')}\n\n"
            f"# ä¸‰ã€å‘æ˜å†…å®¹\n{get_active_content('invention')}\n\n"
            f"# å››ã€é™„å›¾åŠé™„å›¾çš„ç®€å•è¯´æ˜\n{drawings_text if drawings_text else 'ï¼ˆæœ¬ç”³è¯·æ— é™„å›¾ï¼‰'}\n\n"
            f"# äº”ã€å…·ä½“å®æ–½æ–¹å¼\n{get_active_content('implementation')}"
        )
        st.subheader("å®Œæ•´è‰ç¨¿é¢„è§ˆ")
        st.markdown(full_text.replace('\n', '\n\n'))
        st.download_button("ğŸ“„ ä¸‹è½½å®Œæ•´è‰ç¨¿ (.md)", full_text, file_name=f"{title}_patent_draft.md")

if __name__ == "__main__":
    main()